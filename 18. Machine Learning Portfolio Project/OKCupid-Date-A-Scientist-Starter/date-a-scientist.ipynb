{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In recent years, there has been a massive rise in the usage of dating apps to find love. Many of these apps use sophisticated data science techniques to recommend possible matches to users and to optimize the user experience. These apps give us access to a wealth of information that we’ve never had before about how different people experience romance.\n",
    "\n",
    "In this portfolio project, you will analyze some data from OKCupid, an app that focuses on using multiple choice and short answers to match users.\n",
    "\n",
    "You will also create a presentation about your findings from this OKCupid dataset.\n",
    "\n",
    "The purpose of this project is to practice formulating questions and implementing machine learning techniques to answer those questions. However, the questions you ask and how you answer them are entirely up to you.\n",
    "\n",
    "We’re excited to see the different topics you explore.\n",
    "\n",
    "Project Objectives:\n",
    "- Complete a project to add to your portfolio\n",
    "- Use Jupyter Notebook to communicate findings\n",
    "- Build, train, and evaluate a machine learning model\n",
    "\n",
    "Prerequisites:\n",
    "- Natural Language Processing\n",
    "- Supervised Machine Learning\n",
    "- Unsupervised Machine Learning\n",
    "\n",
    "\n",
    "The dataset provided has the following columns of multiple-choice data:\n",
    "\n",
    "- body_type\n",
    "- diet\n",
    "- drinks\n",
    "- drugs\n",
    "- education\n",
    "- ethnicity\n",
    "- height\n",
    "- income\n",
    "- job\n",
    "- offspring\n",
    "- orientation\n",
    "- pets\n",
    "- religion\n",
    "- sex\n",
    "- sign\n",
    "- smokes\n",
    "- speaks\n",
    "- status\n",
    "\n",
    "And a set of open short-answer responses to :\n",
    "\n",
    "- essay0 - My self summary\n",
    "- essay1 - What I’m doing with my life\n",
    "- essay2 - I’m really good at\n",
    "- essay3 - The first thing people usually notice about me\n",
    "- essay4 - Favorite books, movies, show, music, and food\n",
    "- essay5 - The six things I could never do without\n",
    "- essay6 - I spend a lot of time thinking about\n",
    "- essay7 - On a typical Friday night I am\n",
    "- essay8 - The most private thing I am willing to admit\n",
    "- essay9 - You should message me if…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('profiles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>essay0</th>\n",
       "      <th>essay1</th>\n",
       "      <th>essay2</th>\n",
       "      <th>essay3</th>\n",
       "      <th>essay4</th>\n",
       "      <th>essay5</th>\n",
       "      <th>essay6</th>\n",
       "      <th>essay7</th>\n",
       "      <th>essay8</th>\n",
       "      <th>essay9</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>height</th>\n",
       "      <th>income</th>\n",
       "      <th>job</th>\n",
       "      <th>last_online</th>\n",
       "      <th>location</th>\n",
       "      <th>offspring</th>\n",
       "      <th>orientation</th>\n",
       "      <th>pets</th>\n",
       "      <th>religion</th>\n",
       "      <th>sex</th>\n",
       "      <th>sign</th>\n",
       "      <th>smokes</th>\n",
       "      <th>speaks</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>a little extra</td>\n",
       "      <td>strictly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>about me:&lt;br /&gt;\\n&lt;br /&gt;\\ni would love to think...</td>\n",
       "      <td>currently working as an international agent fo...</td>\n",
       "      <td>making people laugh.&lt;br /&gt;\\nranting about a go...</td>\n",
       "      <td>the way i look. i am a six foot half asian, ha...</td>\n",
       "      <td>books:&lt;br /&gt;\\nabsurdistan, the republic, of mi...</td>\n",
       "      <td>food.&lt;br /&gt;\\nwater.&lt;br /&gt;\\ncell phone.&lt;br /&gt;\\n...</td>\n",
       "      <td>duality and humorous things</td>\n",
       "      <td>trying to find someone to hang out with. i am ...</td>\n",
       "      <td>i am new to california and looking for someone...</td>\n",
       "      <td>you want to be swept off your feet!&lt;br /&gt;\\nyou...</td>\n",
       "      <td>asian, white</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>transportation</td>\n",
       "      <td>2012-06-28-20-30</td>\n",
       "      <td>south san francisco, california</td>\n",
       "      <td>doesn&amp;rsquo;t have kids, but might want them</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism and very serious about it</td>\n",
       "      <td>m</td>\n",
       "      <td>gemini</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly other</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>working on space camp</td>\n",
       "      <td>i am a chef: this is what that means.&lt;br /&gt;\\n1...</td>\n",
       "      <td>dedicating everyday to being an unbelievable b...</td>\n",
       "      <td>being silly. having ridiculous amonts of fun w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i am die hard christopher moore fan. i don't r...</td>\n",
       "      <td>delicious porkness in all of its glories.&lt;br /...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i am very open and will share just about anyth...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>white</td>\n",
       "      <td>70.0</td>\n",
       "      <td>80000</td>\n",
       "      <td>hospitality / travel</td>\n",
       "      <td>2012-06-29-21-41</td>\n",
       "      <td>oakland, california</td>\n",
       "      <td>doesn&amp;rsquo;t have kids, but might want them</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism but not too serious about it</td>\n",
       "      <td>m</td>\n",
       "      <td>cancer</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently), spanish (poorly), french (...</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age       body_type               diet    drinks      drugs  \\\n",
       "0   22  a little extra  strictly anything  socially      never   \n",
       "1   35         average       mostly other     often  sometimes   \n",
       "\n",
       "                       education  \\\n",
       "0  working on college/university   \n",
       "1          working on space camp   \n",
       "\n",
       "                                              essay0  \\\n",
       "0  about me:<br />\\n<br />\\ni would love to think...   \n",
       "1  i am a chef: this is what that means.<br />\\n1...   \n",
       "\n",
       "                                              essay1  \\\n",
       "0  currently working as an international agent fo...   \n",
       "1  dedicating everyday to being an unbelievable b...   \n",
       "\n",
       "                                              essay2  \\\n",
       "0  making people laugh.<br />\\nranting about a go...   \n",
       "1  being silly. having ridiculous amonts of fun w...   \n",
       "\n",
       "                                              essay3  \\\n",
       "0  the way i look. i am a six foot half asian, ha...   \n",
       "1                                                NaN   \n",
       "\n",
       "                                              essay4  \\\n",
       "0  books:<br />\\nabsurdistan, the republic, of mi...   \n",
       "1  i am die hard christopher moore fan. i don't r...   \n",
       "\n",
       "                                              essay5  \\\n",
       "0  food.<br />\\nwater.<br />\\ncell phone.<br />\\n...   \n",
       "1  delicious porkness in all of its glories.<br /...   \n",
       "\n",
       "                        essay6  \\\n",
       "0  duality and humorous things   \n",
       "1                          NaN   \n",
       "\n",
       "                                              essay7  \\\n",
       "0  trying to find someone to hang out with. i am ...   \n",
       "1                                                NaN   \n",
       "\n",
       "                                              essay8  \\\n",
       "0  i am new to california and looking for someone...   \n",
       "1  i am very open and will share just about anyth...   \n",
       "\n",
       "                                              essay9     ethnicity  height  \\\n",
       "0  you want to be swept off your feet!<br />\\nyou...  asian, white    75.0   \n",
       "1                                                NaN         white    70.0   \n",
       "\n",
       "   income                   job       last_online  \\\n",
       "0      -1        transportation  2012-06-28-20-30   \n",
       "1   80000  hospitality / travel  2012-06-29-21-41   \n",
       "\n",
       "                          location  \\\n",
       "0  south san francisco, california   \n",
       "1              oakland, california   \n",
       "\n",
       "                                      offspring orientation  \\\n",
       "0  doesn&rsquo;t have kids, but might want them    straight   \n",
       "1  doesn&rsquo;t have kids, but might want them    straight   \n",
       "\n",
       "                        pets                                  religion sex  \\\n",
       "0  likes dogs and likes cats     agnosticism and very serious about it   m   \n",
       "1  likes dogs and likes cats  agnosticism but not too serious about it   m   \n",
       "\n",
       "     sign     smokes                                             speaks  \\\n",
       "0  gemini  sometimes                                            english   \n",
       "1  cancer         no  english (fluently), spanish (poorly), french (...   \n",
       "\n",
       "   status  \n",
       "0  single  \n",
       "1  single  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 31)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 31 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   age          1000 non-null   int64  \n",
      " 1   body_type    926 non-null    object \n",
      " 2   diet         626 non-null    object \n",
      " 3   drinks       946 non-null    object \n",
      " 4   drugs        753 non-null    object \n",
      " 5   education    884 non-null    object \n",
      " 6   essay0       889 non-null    object \n",
      " 7   essay1       865 non-null    object \n",
      " 8   essay2       851 non-null    object \n",
      " 9   essay3       813 non-null    object \n",
      " 10  essay4       813 non-null    object \n",
      " 11  essay5       800 non-null    object \n",
      " 12  essay6       769 non-null    object \n",
      " 13  essay7       772 non-null    object \n",
      " 14  essay8       662 non-null    object \n",
      " 15  essay9       791 non-null    object \n",
      " 16  ethnicity    892 non-null    object \n",
      " 17  height       1000 non-null   float64\n",
      " 18  income       1000 non-null   int64  \n",
      " 19  job          841 non-null    object \n",
      " 20  last_online  1000 non-null   object \n",
      " 21  location     1000 non-null   object \n",
      " 22  offspring    454 non-null    object \n",
      " 23  orientation  1000 non-null   object \n",
      " 24  pets         681 non-null    object \n",
      " 25  religion     651 non-null    object \n",
      " 26  sex          1000 non-null   object \n",
      " 27  sign         822 non-null    object \n",
      " 28  smokes       912 non-null    object \n",
      " 29  speaks       1000 non-null   object \n",
      " 30  status       1000 non-null   object \n",
      "dtypes: float64(1), int64(2), object(28)\n",
      "memory usage: 242.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'essay0': 'my_self', 'essay1': 'life', 'essay2': 'good_at', 'essay3': 'people_notice', \n",
    "                         'essay4': 'favorites', 'essay5': 'six_needed', 'essay6': 'think_to', 'essay7': 'friday_night', \n",
    "                         'essay8': 'private_admit', 'essay9': 'message_me_if'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna('',axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a list with essay columns names\n",
    "essays_cols = df.columns.to_list()[6:16]\n",
    "\n",
    "# Remove newlines and HTML charachters from essay columns\n",
    "for col in essays_cols:\n",
    "    df[col] = df[col].str.replace(\"\\n\", \" \", regex=False)\n",
    "    df[col] = df[col].str.replace(r\"<[^>]*>\", \"\", regex=True)\n",
    "    df[col] = df[col].str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "    df[col] = df[col].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize Essay Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for col in essays_cols:\n",
    "    for row in df[col]:\n",
    "        tokenized_survey = word_tokenize(row)\n",
    "        temp.append([w for w in tokenized_survey if not w in stop_words])\n",
    "    df[col] = temp\n",
    "    temp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>my_self</th>\n",
       "      <th>life</th>\n",
       "      <th>good_at</th>\n",
       "      <th>people_notice</th>\n",
       "      <th>favorites</th>\n",
       "      <th>six_needed</th>\n",
       "      <th>think_to</th>\n",
       "      <th>friday_night</th>\n",
       "      <th>private_admit</th>\n",
       "      <th>message_me_if</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>height</th>\n",
       "      <th>income</th>\n",
       "      <th>job</th>\n",
       "      <th>last_online</th>\n",
       "      <th>location</th>\n",
       "      <th>offspring</th>\n",
       "      <th>orientation</th>\n",
       "      <th>pets</th>\n",
       "      <th>religion</th>\n",
       "      <th>sex</th>\n",
       "      <th>sign</th>\n",
       "      <th>smokes</th>\n",
       "      <th>speaks</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>a little extra</td>\n",
       "      <td>strictly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>[would, love, think, kind, intellectual, eithe...</td>\n",
       "      <td>[currently, working, international, agent, fre...</td>\n",
       "      <td>[making, people, laugh, ranting, good, salting...</td>\n",
       "      <td>[way, look, six, foot, half, asian, half, cauc...</td>\n",
       "      <td>[books, absurdistan, republic, mice, men, book...</td>\n",
       "      <td>[food, water, cell, phone, shelter]</td>\n",
       "      <td>[duality, humorous, things]</td>\n",
       "      <td>[trying, find, someone, hang, anything, except...</td>\n",
       "      <td>[new, california, looking, someone, wisper, se...</td>\n",
       "      <td>[want, swept, feet, tired, norm, want, catch, ...</td>\n",
       "      <td>asian, white</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>transportation</td>\n",
       "      <td>2012-06-28-20-30</td>\n",
       "      <td>south san francisco, california</td>\n",
       "      <td>doesn&amp;rsquo;t have kids, but might want them</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism and very serious about it</td>\n",
       "      <td>m</td>\n",
       "      <td>gemini</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age       body_type               diet    drinks  drugs  \\\n",
       "0   22  a little extra  strictly anything  socially  never   \n",
       "\n",
       "                       education  \\\n",
       "0  working on college/university   \n",
       "\n",
       "                                             my_self  \\\n",
       "0  [would, love, think, kind, intellectual, eithe...   \n",
       "\n",
       "                                                life  \\\n",
       "0  [currently, working, international, agent, fre...   \n",
       "\n",
       "                                             good_at  \\\n",
       "0  [making, people, laugh, ranting, good, salting...   \n",
       "\n",
       "                                       people_notice  \\\n",
       "0  [way, look, six, foot, half, asian, half, cauc...   \n",
       "\n",
       "                                           favorites  \\\n",
       "0  [books, absurdistan, republic, mice, men, book...   \n",
       "\n",
       "                            six_needed                     think_to  \\\n",
       "0  [food, water, cell, phone, shelter]  [duality, humorous, things]   \n",
       "\n",
       "                                        friday_night  \\\n",
       "0  [trying, find, someone, hang, anything, except...   \n",
       "\n",
       "                                       private_admit  \\\n",
       "0  [new, california, looking, someone, wisper, se...   \n",
       "\n",
       "                                       message_me_if     ethnicity  height  \\\n",
       "0  [want, swept, feet, tired, norm, want, catch, ...  asian, white    75.0   \n",
       "\n",
       "   income             job       last_online                         location  \\\n",
       "0      -1  transportation  2012-06-28-20-30  south san francisco, california   \n",
       "\n",
       "                                      offspring orientation  \\\n",
       "0  doesn&rsquo;t have kids, but might want them    straight   \n",
       "\n",
       "                        pets                               religion sex  \\\n",
       "0  likes dogs and likes cats  agnosticism and very serious about it   m   \n",
       "\n",
       "     sign     smokes   speaks  status  \n",
       "0  gemini  sometimes  english  single  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find out how much of a match someone is based on their response to my_self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
