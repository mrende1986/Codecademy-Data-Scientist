{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In recent years, there has been a massive rise in the usage of dating apps to find love. Many of these apps use sophisticated data science techniques to recommend possible matches to users and to optimize the user experience. These apps give us access to a wealth of information that we’ve never had before about how different people experience romance.\n",
    "\n",
    "In this portfolio project, you will analyze some data from OKCupid, an app that focuses on using multiple choice and short answers to match users.\n",
    "\n",
    "You will also create a presentation about your findings from this OKCupid dataset.\n",
    "\n",
    "The purpose of this project is to practice formulating questions and implementing machine learning techniques to answer those questions. However, the questions you ask and how you answer them are entirely up to you.\n",
    "\n",
    "We’re excited to see the different topics you explore.\n",
    "\n",
    "Project Objectives:\n",
    "- Complete a project to add to your portfolio\n",
    "- Use Jupyter Notebook to communicate findings\n",
    "- Build, train, and evaluate a machine learning model\n",
    "\n",
    "Prerequisites:\n",
    "- Natural Language Processing\n",
    "- Supervised Machine Learning\n",
    "- Unsupervised Machine Learning\n",
    "\n",
    "\n",
    "The dataset provided has the following columns of multiple-choice data:\n",
    "\n",
    "- body_type\n",
    "- diet\n",
    "- drinks\n",
    "- drugs\n",
    "- education\n",
    "- ethnicity\n",
    "- height\n",
    "- income\n",
    "- job\n",
    "- offspring\n",
    "- orientation\n",
    "- pets\n",
    "- religion\n",
    "- sex\n",
    "- sign\n",
    "- smokes\n",
    "- speaks\n",
    "- status\n",
    "\n",
    "And a set of open short-answer responses to :\n",
    "\n",
    "- essay0 - My self summary\n",
    "- essay1 - What I’m doing with my life\n",
    "- essay2 - I’m really good at\n",
    "- essay3 - The first thing people usually notice about me\n",
    "- essay4 - Favorite books, movies, show, music, and food\n",
    "- essay5 - The six things I could never do without\n",
    "- essay6 - I spend a lot of time thinking about\n",
    "- essay7 - On a typical Friday night I am\n",
    "- essay8 - The most private thing I am willing to admit\n",
    "- essay9 - You should message me if…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "import re\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords \n",
    "stop_words = set(stopwords.words('english'))\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('profiles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59946, 31)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna('',axis=0,inplace=True)\n",
    "df.rename(columns={'essay0': 'my_self', 'essay1': 'life', 'essay2': 'good_at', 'essay3': 'people_notice', \n",
    "                         'essay4': 'favorites', 'essay5': 'six_needed', 'essay6': 'think_to', 'essay7': 'friday_night', \n",
    "                         'essay8': 'private_admit', 'essay9': 'message_me_if'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since not all the essay questions are populated for every user I am going to consolidate them all into one column called Essay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def essay_prep(data):\n",
    "    \n",
    "    data = data.str.replace(\"\\n\", \" \", regex=False)\n",
    "    data = data.str.replace(r\"<[^>]*>\", \"\", regex=True)\n",
    "    data = data.str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "    data = data.str.lower()\n",
    "    \n",
    "    def remove_numbers(data):\n",
    "        number_pattern = r'\\d+'\n",
    "        data = data.apply(\n",
    "            lambda text: re.sub(pattern=number_pattern, repl=\" \", string=text))\n",
    "        return data\n",
    "    \n",
    "    data = remove_numbers(data)\n",
    "    \n",
    "    def remove_frequent_words(data):\n",
    "        cnt = Counter()\n",
    "        for text in data.values:\n",
    "            for word in text.split(' '):\n",
    "                cnt[word] += 1\n",
    "        FREQWORDS = set([w for (w, wc) in cnt.most_common(10)])\n",
    "        data = data.apply(\n",
    "            lambda text: \" \".join([word for word in str(text).split(' ') if word not in FREQWORDS]))\n",
    "        return data\n",
    "\n",
    "    data = remove_frequent_words(data)\n",
    "    \n",
    "    def lemmatize_words(data):\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        data = data.apply(\n",
    "            lambda text: \" \".join([lemmatizer.lemmatize(word) for word in text.split()]))\n",
    "        return data\n",
    "\n",
    "    data = lemmatize_words(data)\n",
    "    \n",
    "    data = [nlp(data[x]) for x in range(len(data))]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my_self']\n",
      "regex applied\n",
      "remove_numbers applied\n",
      "remove_frequent_words applied\n",
      "lemmatize_words applied\n",
      "nlp data applied\n",
      "['life']\n",
      "regex applied\n",
      "remove_numbers applied\n",
      "remove_frequent_words applied\n",
      "lemmatize_words applied\n",
      "nlp data applied\n",
      "['good_at']\n",
      "regex applied\n",
      "remove_numbers applied\n",
      "remove_frequent_words applied\n",
      "lemmatize_words applied\n",
      "nlp data applied\n",
      "['people_notice']\n",
      "regex applied\n",
      "remove_numbers applied\n",
      "remove_frequent_words applied\n",
      "lemmatize_words applied\n",
      "nlp data applied\n",
      "['favorites']\n",
      "regex applied\n",
      "remove_numbers applied\n",
      "remove_frequent_words applied\n",
      "lemmatize_words applied\n",
      "nlp data applied\n",
      "['six_needed']\n",
      "regex applied\n",
      "remove_numbers applied\n",
      "remove_frequent_words applied\n",
      "lemmatize_words applied\n",
      "nlp data applied\n",
      "['think_to']\n",
      "regex applied\n",
      "remove_numbers applied\n",
      "remove_frequent_words applied\n",
      "lemmatize_words applied\n",
      "nlp data applied\n",
      "['friday_night']\n",
      "regex applied\n",
      "remove_numbers applied\n",
      "remove_frequent_words applied\n",
      "lemmatize_words applied\n",
      "nlp data applied\n",
      "['private_admit']\n",
      "regex applied\n",
      "remove_numbers applied\n",
      "remove_frequent_words applied\n",
      "lemmatize_words applied\n",
      "nlp data applied\n",
      "['message_me_if']\n",
      "regex applied\n",
      "remove_numbers applied\n",
      "remove_frequent_words applied\n",
      "lemmatize_words applied\n",
      "nlp data applied\n"
     ]
    }
   ],
   "source": [
    "essays_cols = df.columns.to_list()[6:16]\n",
    "\n",
    "for col in essays_cols:\n",
    "    print([col])\n",
    "    df[col] = essay_prep(df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the best match\n",
    "#### Based on responses to essay questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "userid = 0\n",
    "essays_cols = df.columns.to_list()[6:16]\n",
    "\n",
    "def find_best_match(data):\n",
    "    essays_cols = data.columns.to_list()[6:16]\n",
    "    temp_list = []\n",
    "    def userid_v_others(data):\n",
    "        for i in range(len(data)):\n",
    "            temp_list.append(data[userid].similarity(data[i]))\n",
    "        return temp_list\n",
    "\n",
    "    for col in essays_cols:\n",
    "        temp_list = []\n",
    "        data[str(col)+'_score'] = userid_v_others(data[col])\n",
    "\n",
    "    def orientation(data):\n",
    "        if data.orientation.iloc[userid] == 'straight' and data.sex.iloc[userid] == 'm':\n",
    "            return data[(data.orientation == 'straight') & (data.sex == 'f')]\n",
    "        if data.orientation.iloc[userid] == 'straight' and data.sex.iloc[userid] == 'f':\n",
    "            return data[(data.orientation == 'straight') & (data.sex == 'm')]\n",
    "        elif data.orientation.iloc[userid] == 'gay' and data.sex.iloc[userid] == 'm':\n",
    "            return data[(data.orientation == 'gay') & (data.sex == 'm')]\n",
    "        elif data.orientation.iloc[userid] == 'gay' and data.sex.iloc[userid] == 'f':\n",
    "            return data[(data.orientation == 'gay') & (data.sex == 'f')]\n",
    "        elif data.orientation.iloc[userid] == 'bisexual':\n",
    "            return data[data.orientation == 'bisexual']\n",
    "        return data\n",
    "\n",
    "    data = orientation(data)\n",
    "    \n",
    "    # Calculate Average Score of matched essays\n",
    "    data['essay_match'] = data.iloc[: , -10:].mean(axis=1)\n",
    "    \n",
    "    # Sort top 10 highest match\n",
    "    data = data.sort_values(['essay_match'],ascending=False).head()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrend\\AppData\\Local\\Temp/ipykernel_12768/1144234782.py:9: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  temp_list.append(data[userid].similarity(data[i]))\n",
      "C:\\Users\\mrend\\AppData\\Local\\Temp/ipykernel_12768/1144234782.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['essay_match'] = data.iloc[: , -10:].mean(axis=1)\n"
     ]
    }
   ],
   "source": [
    "best_match = find_best_match(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>my_self</th>\n",
       "      <th>life</th>\n",
       "      <th>good_at</th>\n",
       "      <th>people_notice</th>\n",
       "      <th>favorites</th>\n",
       "      <th>six_needed</th>\n",
       "      <th>think_to</th>\n",
       "      <th>friday_night</th>\n",
       "      <th>private_admit</th>\n",
       "      <th>message_me_if</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>height</th>\n",
       "      <th>income</th>\n",
       "      <th>job</th>\n",
       "      <th>last_online</th>\n",
       "      <th>location</th>\n",
       "      <th>offspring</th>\n",
       "      <th>orientation</th>\n",
       "      <th>pets</th>\n",
       "      <th>religion</th>\n",
       "      <th>sex</th>\n",
       "      <th>sign</th>\n",
       "      <th>smokes</th>\n",
       "      <th>speaks</th>\n",
       "      <th>status</th>\n",
       "      <th>my_self_score</th>\n",
       "      <th>life_score</th>\n",
       "      <th>good_at_score</th>\n",
       "      <th>people_notice_score</th>\n",
       "      <th>favorites_score</th>\n",
       "      <th>six_needed_score</th>\n",
       "      <th>think_to_score</th>\n",
       "      <th>friday_night_score</th>\n",
       "      <th>private_admit_score</th>\n",
       "      <th>message_me_if_score</th>\n",
       "      <th>essay_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43284</th>\n",
       "      <td>25</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>working on ph.d program</td>\n",
       "      <td>(onequarter, nerd, onequarter, explorer, onesi...</td>\n",
       "      <td>(left, new, zealand, for, california, three, y...</td>\n",
       "      <td>(smiling, raising, one, eyebrow, time, baking,...</td>\n",
       "      <td>(think, this, depends, on, context, in, which,...</td>\n",
       "      <td>(think, taste, book, movie, make, me, out, be,...</td>\n",
       "      <td>(warm, blanket, comfortable, shoe, good, laugh...</td>\n",
       "      <td>(concept, god, religion, science, determinism,...</td>\n",
       "      <td>(doing, something, low, key, like, going, rest...</td>\n",
       "      <td>(do, nt, have, any, secret, often, share, more...</td>\n",
       "      <td>(idea, church, doe, not, send, running, for, n...</td>\n",
       "      <td>indian</td>\n",
       "      <td>63.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>student</td>\n",
       "      <td>2012-06-24-15-14</td>\n",
       "      <td>berkeley, california</td>\n",
       "      <td></td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and dislikes cats</td>\n",
       "      <td>catholicism and somewhat serious about it</td>\n",
       "      <td>f</td>\n",
       "      <td>aquarius and it&amp;rsquo;s fun to think about</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently)</td>\n",
       "      <td>single</td>\n",
       "      <td>0.974263</td>\n",
       "      <td>0.925613</td>\n",
       "      <td>0.804371</td>\n",
       "      <td>0.925844</td>\n",
       "      <td>0.912147</td>\n",
       "      <td>0.674843</td>\n",
       "      <td>0.669407</td>\n",
       "      <td>0.891630</td>\n",
       "      <td>0.807152</td>\n",
       "      <td>0.926472</td>\n",
       "      <td>0.851174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4455</th>\n",
       "      <td>24</td>\n",
       "      <td></td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>(hi, there, really, is, nt, much, for, me, say...</td>\n",
       "      <td>(came, back, from, studying, abroad, uk, miss,...</td>\n",
       "      <td>(finding, positive, in, all, negative, like, s...</td>\n",
       "      <td>(probably, me, laughing, tend, laugh, lot, at,...</td>\n",
       "      <td>(book, complete, work, sherlock, holmes, bridg...</td>\n",
       "      <td>(music, cell, phone, good, food, laughter)</td>\n",
       "      <td>(future, all, possibility, because, they, are,...</td>\n",
       "      <td>(either, at, home, staying, in, watching, good...</td>\n",
       "      <td>(like, sing, mostly, myself, tend, have, song,...</td>\n",
       "      <td>(want, meet, somebody, new, just, want, chat, ...</td>\n",
       "      <td>asian</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>other</td>\n",
       "      <td>2012-06-28-23-18</td>\n",
       "      <td>rodeo, california</td>\n",
       "      <td></td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>catholicism but not too serious about it</td>\n",
       "      <td>f</td>\n",
       "      <td>pisces and it&amp;rsquo;s fun to think about</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently), spanish (okay)</td>\n",
       "      <td>single</td>\n",
       "      <td>0.982187</td>\n",
       "      <td>0.910961</td>\n",
       "      <td>0.775361</td>\n",
       "      <td>0.919054</td>\n",
       "      <td>0.920145</td>\n",
       "      <td>0.829580</td>\n",
       "      <td>0.550076</td>\n",
       "      <td>0.913259</td>\n",
       "      <td>0.773535</td>\n",
       "      <td>0.926720</td>\n",
       "      <td>0.850088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42377</th>\n",
       "      <td>29</td>\n",
       "      <td>fit</td>\n",
       "      <td>mostly vegetarian</td>\n",
       "      <td>socially</td>\n",
       "      <td></td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>(an, interview, interviewer, thanks, for, comi...</td>\n",
       "      <td>(so, past, you, ve, written, some, poetry, her...</td>\n",
       "      <td>(where, do, you, have, some, talent, situation...</td>\n",
       "      <td>(what, s, first, thing, going, notice, when, l...</td>\n",
       "      <td>(list, list, list, i, m, just, going, come, ou...</td>\n",
       "      <td>(let, just, say, that, you, already, have, foo...</td>\n",
       "      <td>(so, what, s, your, thinkpot, filled, with, th...</td>\n",
       "      <td>(what, s, your, social, life, looking, like, t...</td>\n",
       "      <td>(give, u, some, juicy, dirty, secret, feminist...</td>\n",
       "      <td>(why, should, someone, contact, they, made, it...</td>\n",
       "      <td>white</td>\n",
       "      <td>65.0</td>\n",
       "      <td>30000</td>\n",
       "      <td>other</td>\n",
       "      <td>2012-06-28-14-42</td>\n",
       "      <td>berkeley, california</td>\n",
       "      <td></td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>other</td>\n",
       "      <td>f</td>\n",
       "      <td>virgo</td>\n",
       "      <td>no</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "      <td>0.965347</td>\n",
       "      <td>0.881772</td>\n",
       "      <td>0.816727</td>\n",
       "      <td>0.938160</td>\n",
       "      <td>0.899005</td>\n",
       "      <td>0.693550</td>\n",
       "      <td>0.642792</td>\n",
       "      <td>0.926690</td>\n",
       "      <td>0.815970</td>\n",
       "      <td>0.918816</td>\n",
       "      <td>0.849883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57338</th>\n",
       "      <td>35</td>\n",
       "      <td>thin</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td></td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>(true, story, behind, this, profile, is, one, ...</td>\n",
       "      <td>(trying, take, it, day, by, day, sometimes, se...</td>\n",
       "      <td>(staying, up, all, night, thinking, about, eve...</td>\n",
       "      <td>(have, redhairor, auburn, be, exact, look, you...</td>\n",
       "      <td>(joe, meno, hunter, s, thompson, chuck, palahn...</td>\n",
       "      <td>(coffee, soft, comforter, good, conversation, ...</td>\n",
       "      <td>(oh, please, find, switch, calm, worried, head...</td>\n",
       "      <td>(why, must, it, be, friday, how, about, tuesda...</td>\n",
       "      <td>(am, an, open, book, but, you, will, have, tak...</td>\n",
       "      <td>(can, hold, conversation, make, me, laugh, wil...</td>\n",
       "      <td>white</td>\n",
       "      <td>67.0</td>\n",
       "      <td>30000</td>\n",
       "      <td>medicine / health</td>\n",
       "      <td>2012-06-30-20-19</td>\n",
       "      <td>san mateo, california</td>\n",
       "      <td></td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>christianity but not too serious about it</td>\n",
       "      <td>f</td>\n",
       "      <td>cancer and it&amp;rsquo;s fun to think about</td>\n",
       "      <td></td>\n",
       "      <td>english (fluently), german (okay), japanese (p...</td>\n",
       "      <td>single</td>\n",
       "      <td>0.984959</td>\n",
       "      <td>0.927562</td>\n",
       "      <td>0.822452</td>\n",
       "      <td>0.944342</td>\n",
       "      <td>0.924152</td>\n",
       "      <td>0.628592</td>\n",
       "      <td>0.605569</td>\n",
       "      <td>0.916261</td>\n",
       "      <td>0.807689</td>\n",
       "      <td>0.936935</td>\n",
       "      <td>0.849851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54274</th>\n",
       "      <td>34</td>\n",
       "      <td>fit</td>\n",
       "      <td></td>\n",
       "      <td>socially</td>\n",
       "      <td></td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>(hm, tigertamer, synchronized, swimming, chore...</td>\n",
       "      <td>(making, thing, all, kind, head, with, hand, f...</td>\n",
       "      <td>(playing, thinking, way, remind, u, that, we, ...</td>\n",
       "      <td>(spectacular, dog, by, side, no, do, nt, know,...</td>\n",
       "      <td>(read, way, le, than, wish, did, these, day, b...</td>\n",
       "      <td>(music, good, black, ink, pen, preferably, pil...</td>\n",
       "      <td>(accept, address, appreciate, that, art, is, s...</td>\n",
       "      <td>(driving, up, route, good, songlist, notebook,...</td>\n",
       "      <td>(turned, off, by, men, who, use, term, baby, d...</td>\n",
       "      <td>(need, someone, make, song, scene, picture, st...</td>\n",
       "      <td>white</td>\n",
       "      <td>64.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>artistic / musical / writer</td>\n",
       "      <td>2012-06-30-01-18</td>\n",
       "      <td>mill valley, california</td>\n",
       "      <td></td>\n",
       "      <td>straight</td>\n",
       "      <td>has dogs</td>\n",
       "      <td>agnosticism</td>\n",
       "      <td>f</td>\n",
       "      <td>pisces and it&amp;rsquo;s fun to think about</td>\n",
       "      <td>no</td>\n",
       "      <td>english, french (okay)</td>\n",
       "      <td>single</td>\n",
       "      <td>0.979010</td>\n",
       "      <td>0.920432</td>\n",
       "      <td>0.803636</td>\n",
       "      <td>0.929837</td>\n",
       "      <td>0.871048</td>\n",
       "      <td>0.691017</td>\n",
       "      <td>0.641640</td>\n",
       "      <td>0.914959</td>\n",
       "      <td>0.809861</td>\n",
       "      <td>0.930192</td>\n",
       "      <td>0.849163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age body_type               diet    drinks  drugs  \\\n",
       "43284   25   average    mostly anything  socially  never   \n",
       "4455    24              mostly anything  socially  never   \n",
       "42377   29       fit  mostly vegetarian  socially          \n",
       "57338   35      thin    mostly anything  socially          \n",
       "54274   34       fit                     socially          \n",
       "\n",
       "                               education  \\\n",
       "43284            working on ph.d program   \n",
       "4455   graduated from college/university   \n",
       "42377  graduated from college/university   \n",
       "57338  graduated from college/university   \n",
       "54274  graduated from college/university   \n",
       "\n",
       "                                                 my_self  \\\n",
       "43284  (onequarter, nerd, onequarter, explorer, onesi...   \n",
       "4455   (hi, there, really, is, nt, much, for, me, say...   \n",
       "42377  (an, interview, interviewer, thanks, for, comi...   \n",
       "57338  (true, story, behind, this, profile, is, one, ...   \n",
       "54274  (hm, tigertamer, synchronized, swimming, chore...   \n",
       "\n",
       "                                                    life  \\\n",
       "43284  (left, new, zealand, for, california, three, y...   \n",
       "4455   (came, back, from, studying, abroad, uk, miss,...   \n",
       "42377  (so, past, you, ve, written, some, poetry, her...   \n",
       "57338  (trying, take, it, day, by, day, sometimes, se...   \n",
       "54274  (making, thing, all, kind, head, with, hand, f...   \n",
       "\n",
       "                                                 good_at  \\\n",
       "43284  (smiling, raising, one, eyebrow, time, baking,...   \n",
       "4455   (finding, positive, in, all, negative, like, s...   \n",
       "42377  (where, do, you, have, some, talent, situation...   \n",
       "57338  (staying, up, all, night, thinking, about, eve...   \n",
       "54274  (playing, thinking, way, remind, u, that, we, ...   \n",
       "\n",
       "                                           people_notice  \\\n",
       "43284  (think, this, depends, on, context, in, which,...   \n",
       "4455   (probably, me, laughing, tend, laugh, lot, at,...   \n",
       "42377  (what, s, first, thing, going, notice, when, l...   \n",
       "57338  (have, redhairor, auburn, be, exact, look, you...   \n",
       "54274  (spectacular, dog, by, side, no, do, nt, know,...   \n",
       "\n",
       "                                               favorites  \\\n",
       "43284  (think, taste, book, movie, make, me, out, be,...   \n",
       "4455   (book, complete, work, sherlock, holmes, bridg...   \n",
       "42377  (list, list, list, i, m, just, going, come, ou...   \n",
       "57338  (joe, meno, hunter, s, thompson, chuck, palahn...   \n",
       "54274  (read, way, le, than, wish, did, these, day, b...   \n",
       "\n",
       "                                              six_needed  \\\n",
       "43284  (warm, blanket, comfortable, shoe, good, laugh...   \n",
       "4455          (music, cell, phone, good, food, laughter)   \n",
       "42377  (let, just, say, that, you, already, have, foo...   \n",
       "57338  (coffee, soft, comforter, good, conversation, ...   \n",
       "54274  (music, good, black, ink, pen, preferably, pil...   \n",
       "\n",
       "                                                think_to  \\\n",
       "43284  (concept, god, religion, science, determinism,...   \n",
       "4455   (future, all, possibility, because, they, are,...   \n",
       "42377  (so, what, s, your, thinkpot, filled, with, th...   \n",
       "57338  (oh, please, find, switch, calm, worried, head...   \n",
       "54274  (accept, address, appreciate, that, art, is, s...   \n",
       "\n",
       "                                            friday_night  \\\n",
       "43284  (doing, something, low, key, like, going, rest...   \n",
       "4455   (either, at, home, staying, in, watching, good...   \n",
       "42377  (what, s, your, social, life, looking, like, t...   \n",
       "57338  (why, must, it, be, friday, how, about, tuesda...   \n",
       "54274  (driving, up, route, good, songlist, notebook,...   \n",
       "\n",
       "                                           private_admit  \\\n",
       "43284  (do, nt, have, any, secret, often, share, more...   \n",
       "4455   (like, sing, mostly, myself, tend, have, song,...   \n",
       "42377  (give, u, some, juicy, dirty, secret, feminist...   \n",
       "57338  (am, an, open, book, but, you, will, have, tak...   \n",
       "54274  (turned, off, by, men, who, use, term, baby, d...   \n",
       "\n",
       "                                           message_me_if ethnicity height  \\\n",
       "43284  (idea, church, doe, not, send, running, for, n...    indian   63.0   \n",
       "4455   (want, meet, somebody, new, just, want, chat, ...     asian   60.0   \n",
       "42377  (why, should, someone, contact, they, made, it...     white   65.0   \n",
       "57338  (can, hold, conversation, make, me, laugh, wil...     white   67.0   \n",
       "54274  (need, someone, make, song, scene, picture, st...     white   64.0   \n",
       "\n",
       "       income                          job       last_online  \\\n",
       "43284      -1                      student  2012-06-24-15-14   \n",
       "4455       -1                        other  2012-06-28-23-18   \n",
       "42377   30000                        other  2012-06-28-14-42   \n",
       "57338   30000            medicine / health  2012-06-30-20-19   \n",
       "54274      -1  artistic / musical / writer  2012-06-30-01-18   \n",
       "\n",
       "                      location offspring orientation  \\\n",
       "43284     berkeley, california              straight   \n",
       "4455         rodeo, california              straight   \n",
       "42377     berkeley, california              straight   \n",
       "57338    san mateo, california              straight   \n",
       "54274  mill valley, california              straight   \n",
       "\n",
       "                               pets  \\\n",
       "43284  likes dogs and dislikes cats   \n",
       "4455      likes dogs and likes cats   \n",
       "42377     likes dogs and likes cats   \n",
       "57338     likes dogs and likes cats   \n",
       "54274                      has dogs   \n",
       "\n",
       "                                        religion sex  \\\n",
       "43284  catholicism and somewhat serious about it   f   \n",
       "4455    catholicism but not too serious about it   f   \n",
       "42377                                      other   f   \n",
       "57338  christianity but not too serious about it   f   \n",
       "54274                                agnosticism   f   \n",
       "\n",
       "                                             sign smokes  \\\n",
       "43284  aquarius and it&rsquo;s fun to think about     no   \n",
       "4455     pisces and it&rsquo;s fun to think about     no   \n",
       "42377                                       virgo     no   \n",
       "57338    cancer and it&rsquo;s fun to think about          \n",
       "54274    pisces and it&rsquo;s fun to think about     no   \n",
       "\n",
       "                                                  speaks  status  \\\n",
       "43284                                 english (fluently)  single   \n",
       "4455                  english (fluently), spanish (okay)  single   \n",
       "42377                                            english  single   \n",
       "57338  english (fluently), german (okay), japanese (p...  single   \n",
       "54274                             english, french (okay)  single   \n",
       "\n",
       "       my_self_score  life_score  good_at_score  people_notice_score  \\\n",
       "43284       0.974263    0.925613       0.804371             0.925844   \n",
       "4455        0.982187    0.910961       0.775361             0.919054   \n",
       "42377       0.965347    0.881772       0.816727             0.938160   \n",
       "57338       0.984959    0.927562       0.822452             0.944342   \n",
       "54274       0.979010    0.920432       0.803636             0.929837   \n",
       "\n",
       "       favorites_score  six_needed_score  think_to_score  friday_night_score  \\\n",
       "43284         0.912147          0.674843        0.669407            0.891630   \n",
       "4455          0.920145          0.829580        0.550076            0.913259   \n",
       "42377         0.899005          0.693550        0.642792            0.926690   \n",
       "57338         0.924152          0.628592        0.605569            0.916261   \n",
       "54274         0.871048          0.691017        0.641640            0.914959   \n",
       "\n",
       "       private_admit_score  message_me_if_score  essay_match  \n",
       "43284             0.807152             0.926472     0.851174  \n",
       "4455              0.773535             0.926720     0.850088  \n",
       "42377             0.815970             0.918816     0.849883  \n",
       "57338             0.807689             0.936935     0.849851  \n",
       "54274             0.809861             0.930192     0.849163  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_match.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
